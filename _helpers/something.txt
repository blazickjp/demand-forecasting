I'm thinking about the most useful information to feed into an LLMs context for programming questions. For example, say we're having a conversation and weâ€™re having a conversation about something I'm working on. You don't have any context to see because you can't see my repo and files. My working directory is missing from your context, I have new packages missing from your training data, and I have a limited context window to work with. I can store my current repo in a vector database, then query the DB for relevant content each time I send a message, but I'm not sure what the most relevant information to feed really is! Should I include function / class definitions directly? Are tutorials better information to have in the DB? GitHub issues? Tweets? Everything? If everything, then how do I keep the junk out the context? We only have few thousand tokens to work with (4K for most models). I also need to keep the conversation history in there and the system level prompt. How would Donald Knuth design a system to solve this?