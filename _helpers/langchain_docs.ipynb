{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.document_loaders import GitLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from scrape_and_load_langchain import PythonClassDirectoryLoader\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, StructuredChatAgent, AgentExecutor\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents.self_ask_with_search.base import SelfAskWithSearchAgent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PINECONE='5d4ffa0d-2615-4348-ac65-a3071404be6b'\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return True if file_path.endswith(\".md\") else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagesPlaceholder(variable_name='chat_history')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(allowed_special=\"all\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "class_loader = PythonClassDirectoryLoader(\"/Users/josephblazick/Documents/langchain\", glob=\"**/*.py\")\n",
    "class_loader.load()\n",
    "git_loader = GitLoader(repo_path=\"/Users/josephblazick/Documents/langchain\", branch=\"v0.0.196\", file_filter=file_filter)\n",
    "package_docs = git_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(package_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_docs(question: str):\n",
    "    \"\"\"\n",
    "    Answers your question using the markdown files found in the langchain documeentation repository.\n",
    "    This function is best used when you want examples of how to use particular classes or functions.\n",
    "    \"\"\"\n",
    "    documents = docsearch.similarity_search(question, k = 10)\n",
    "    qa_chain = load_qa_chain(ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"), chain_type=\"refine\")\n",
    "    return qa_chain.run({\"input_documents\": documents, \"question\": question})\n",
    "\n",
    "def summary_docs(question: str):\n",
    "    \"\"\"\n",
    "    Give a summary of documents retrieved from the markdown files found in the langchain documeentation repository.\n",
    "    This function is best used when you want a general summary of how to use langchain modules or classes.\n",
    "    \"\"\"\n",
    "    documents = docsearch.similarity_search(question, k = 10)\n",
    "    sum_chain = load_summarize_chain(ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"), chain_type=\"map_reduce\")\n",
    "    return sum_chain.run({\"input_documents\": documents, \"question\": question})\n",
    "\n",
    "def class_lookup(item: str):\n",
    "    \"\"\"\n",
    "    Lookup for class definitions in the langchain codebase. You should use this function when you need to see the source code\n",
    "    related to a particular class.\n",
    "    \"\"\"\n",
    "    return class_loader.get_class(item)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=qa_docs,\n",
    "        name=\"Questions about Langchain codebase\",\n",
    "        description=\"Answers your question using the markdown files found in the langchain documeentation repository. This function is best used when you want examples of how to use particular classes or functions. Your input should be as descriptive as possible to ensure documents returned are as relevant as possible.\",\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=summary_docs,\n",
    "        name=\"Summarise langchain docs\",\n",
    "        description=\"Give a summary of documents retrieved from the markdown files found in the langchain documeentation repository. This function is best used when you want a general summary of how to use langchain modules or classes. Your input should be as descriptive as possible to ensure documents returned are as relevant as possible.\",\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=class_lookup,\n",
    "        name=\"LangChain Class Lookup\",\n",
    "        description=\"Lookup for class definitions in the langchain codebase. You should use this function when you need to see the source code related to a particular class\",\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = SelfAskWithSearchAgent.create_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent_type=AgentType.SELF_ASK_WITH_SEARCH, \n",
    "    llm=ChatOpenAI(temperature=0.5, model=\"gpt-4\"), \n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# planner = load_chat_planner(ChatOpenAI(temperature=0.5, model=\"gpt-4\"))\n",
    "# executor = load_agent_executor(ChatOpenAI(temperature=0.0, model=\"gpt-4\"), tools=tools, verbose=True)\n",
    "# agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `I should find an example of how to access the prompt using the AgentExecutor object in the langchain documentation.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m'''\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    How do i access the prompt of this? The initialize_agent function returns a AgentExecutor object.\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    from langchain.agents import AgentType, initialize_agent, Tool\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    agent = initialize_agent(\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m    tools=tools,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m    agent_type=AgentType.SELF_ASK_WITH_SEARCH, \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    llm=ChatOpenAI(temperature=0.5, model=\"gpt-4\"), \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m    verbose=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    '''\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py:256\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py:953\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 953\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    954\u001b[0m         name_to_tool_map,\n\u001b[1;32m    955\u001b[0m         color_mapping,\n\u001b[1;32m    956\u001b[0m         inputs,\n\u001b[1;32m    957\u001b[0m         intermediate_steps,\n\u001b[1;32m    958\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    961\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    962\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    963\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py:773\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    771\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    774\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    763\u001b[0m         intermediate_steps,\n\u001b[1;32m    764\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    765\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/mrkl/output_parser.py:42\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     38\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: text\u001b[39m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()}, text\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*?)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format: Missing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAction:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m after \u001b[39m\u001b[39m'\u001b[39m\u001b[39mThought:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m         llm_output\u001b[39m=\u001b[39mtext,\n\u001b[1;32m     46\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\n\u001b[1;32m     49\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*Action\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*Input\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     52\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `I should find an example of how to access the prompt using the AgentExecutor object in the langchain documentation.`"
     ]
    }
   ],
   "source": [
    "agent.run(\n",
    "    '''\n",
    "    How do i access the prompt of this? The initialize_agent function returns a AgentExecutor object.\n",
    "    from langchain.agents import AgentType, initialize_agent, Tool\n",
    "\n",
    "    agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent_type=AgentType.SELF_ASK_WITH_SEARCH, \n",
    "    llm=ChatOpenAI(temperature=0.5, model=\"gpt-4\"), \n",
    "    verbose=True,\n",
    ")\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the 'AgentExecutor' class and its attributes.\n",
      "Action: LangChain Class Lookup\n",
      "Action Input: AgentExecutor\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mclass AgentExecutor(Chain):\n",
      "    \"\"\"Consists of an agent using tools.\"\"\"\n",
      "    agent: Union[BaseSingleActionAgent, BaseMultiActionAgent]\n",
      "    tools: Sequence[BaseTool]\n",
      "    return_intermediate_steps: bool = False\n",
      "    max_iterations: Optional[int] = 15\n",
      "    max_execution_time: Optional[float] = None\n",
      "    early_stopping_method: str = 'force'\n",
      "    handle_parsing_errors: Union[bool, str, Callable[[OutputParserException], str]] = False\n",
      "\n",
      "    @classmethod\n",
      "    def from_agent_and_tools(cls, agent: Union[BaseSingleActionAgent, BaseMultiActionAgent], tools: Sequence[BaseTool], callback_manager: Optional[BaseCallbackManager]=None, **kwargs: Any) -> AgentExecutor:\n",
      "        \"\"\"Create from agent and tools.\"\"\"\n",
      "        return cls(agent=agent, tools=tools, callback_manager=callback_manager, **kwargs)\n",
      "\n",
      "    @root_validator()\n",
      "    def validate_tools(cls, values: Dict) -> Dict:\n",
      "        \"\"\"Validate that tools are compatible with agent.\"\"\"\n",
      "        agent = values['agent']\n",
      "        tools = values['tools']\n",
      "        allowed_tools = agent.get_allowed_tools()\n",
      "        if allowed_tools is not None:\n",
      "            if set(allowed_tools) != set([tool.name for tool in tools]):\n",
      "                raise ValueError(f'Allowed tools ({allowed_tools}) different than provided tools ({[tool.name for tool in tools]})')\n",
      "        return values\n",
      "\n",
      "    @root_validator()\n",
      "    def validate_return_direct_tool(cls, values: Dict) -> Dict:\n",
      "        \"\"\"Validate that tools are compatible with agent.\"\"\"\n",
      "        agent = values['agent']\n",
      "        tools = values['tools']\n",
      "        if isinstance(agent, BaseMultiActionAgent):\n",
      "            for tool in tools:\n",
      "                if tool.return_direct:\n",
      "                    raise ValueError('Tools that have `return_direct=True` are not allowed in multi-action agents')\n",
      "        return values\n",
      "\n",
      "    def save(self, file_path: Union[Path, str]) -> None:\n",
      "        \"\"\"Raise error - saving not supported for Agent Executors.\"\"\"\n",
      "        raise ValueError('Saving not supported for agent executors. If you are trying to save the agent, please use the `.save_agent(...)`')\n",
      "\n",
      "    def save_agent(self, file_path: Union[Path, str]) -> None:\n",
      "        \"\"\"Save the underlying agent.\"\"\"\n",
      "        return self.agent.save(file_path)\n",
      "\n",
      "    @property\n",
      "    def input_keys(self) -> List[str]:\n",
      "        \"\"\"Return the input keys.\n",
      "\n",
      "        :meta private:\n",
      "        \"\"\"\n",
      "        return self.agent.input_keys\n",
      "\n",
      "    @property\n",
      "    def output_keys(self) -> List[str]:\n",
      "        \"\"\"Return the singular output key.\n",
      "\n",
      "        :meta private:\n",
      "        \"\"\"\n",
      "        if self.return_intermediate_steps:\n",
      "            return self.agent.return_values + ['intermediate_steps']\n",
      "        else:\n",
      "            return self.agent.return_values\n",
      "\n",
      "    def lookup_tool(self, name: str) -> BaseTool:\n",
      "        \"\"\"Lookup tool by name.\"\"\"\n",
      "        return {tool.name: tool for tool in self.tools}[name]\n",
      "\n",
      "    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\n",
      "        if self.max_iterations is not None and iterations >= self.max_iterations:\n",
      "            return False\n",
      "        if self.max_execution_time is not None and time_elapsed >= self.max_execution_time:\n",
      "            return False\n",
      "        return True\n",
      "\n",
      "    def _return(self, output: AgentFinish, intermediate_steps: list, run_manager: Optional[CallbackManagerForChainRun]=None) -> Dict[str, Any]:\n",
      "        if run_manager:\n",
      "            run_manager.on_agent_finish(output, color='green', verbose=self.verbose)\n",
      "        final_output = output.return_values\n",
      "        if self.return_intermediate_steps:\n",
      "            final_output['intermediate_steps'] = intermediate_steps\n",
      "        return final_output\n",
      "\n",
      "    async def _areturn(self, output: AgentFinish, intermediate_steps: list, run_manager: Optional[AsyncCallbackManagerForChainRun]=None) -> Dict[str, Any]:\n",
      "        if run_manager:\n",
      "            await run_manager.on_agent_finish(output, color='green', verbose=self.verbose)\n",
      "        final_output = output.return_values\n",
      "        if self.return_intermediate_steps:\n",
      "            final_output['intermediate_steps'] = intermediate_steps\n",
      "        return final_output\n",
      "\n",
      "    def _take_next_step(self, name_to_tool_map: Dict[str, BaseTool], color_mapping: Dict[str, str], inputs: Dict[str, str], intermediate_steps: List[Tuple[AgentAction, str]], run_manager: Optional[CallbackManagerForChainRun]=None) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n",
      "        \"\"\"Take a single step in the thought-action-observation loop.\n",
      "\n",
      "        Override this to take control of how the agent makes and acts on choices.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            output = self.agent.plan(intermediate_steps, callbacks=run_manager.get_child() if run_manager else None, **inputs)\n",
      "        except OutputParserException as e:\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                raise_error = not self.handle_parsing_errors\n",
      "            else:\n",
      "                raise_error = False\n",
      "            if raise_error:\n",
      "                raise e\n",
      "            text = str(e)\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                if e.send_to_llm:\n",
      "                    observation = str(e.observation)\n",
      "                    text = str(e.llm_output)\n",
      "                else:\n",
      "                    observation = 'Invalid or incomplete response'\n",
      "            elif isinstance(self.handle_parsing_errors, str):\n",
      "                observation = self.handle_parsing_errors\n",
      "            elif callable(self.handle_parsing_errors):\n",
      "                observation = self.handle_parsing_errors(e)\n",
      "            else:\n",
      "                raise ValueError('Got unexpected type of `handle_parsing_errors`')\n",
      "            output = AgentAction('_Exception', observation, text)\n",
      "            if run_manager:\n",
      "                run_manager.on_agent_action(output, color='green')\n",
      "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "            observation = ExceptionTool().run(output.tool_input, verbose=self.verbose, color=None, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            return [(output, observation)]\n",
      "        if isinstance(output, AgentFinish):\n",
      "            return output\n",
      "        actions: List[AgentAction]\n",
      "        if isinstance(output, AgentAction):\n",
      "            actions = [output]\n",
      "        else:\n",
      "            actions = output\n",
      "        result = []\n",
      "        for agent_action in actions:\n",
      "            if run_manager:\n",
      "                run_manager.on_agent_action(agent_action, color='green')\n",
      "            if agent_action.tool in name_to_tool_map:\n",
      "                tool = name_to_tool_map[agent_action.tool]\n",
      "                return_direct = tool.return_direct\n",
      "                color = color_mapping[agent_action.tool]\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                if return_direct:\n",
      "                    tool_run_kwargs['llm_prefix'] = ''\n",
      "                observation = tool.run(agent_action.tool_input, verbose=self.verbose, color=color, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            else:\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                observation = InvalidTool().run(agent_action.tool, verbose=self.verbose, color=None, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            result.append((agent_action, observation))\n",
      "        return result\n",
      "\n",
      "    async def _atake_next_step(self, name_to_tool_map: Dict[str, BaseTool], color_mapping: Dict[str, str], inputs: Dict[str, str], intermediate_steps: List[Tuple[AgentAction, str]], run_manager: Optional[AsyncCallbackManagerForChainRun]=None) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n",
      "        \"\"\"Take a single step in the thought-action-observation loop.\n",
      "\n",
      "        Override this to take control of how the agent makes and acts on choices.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            output = await self.agent.aplan(intermediate_steps, callbacks=run_manager.get_child() if run_manager else None, **inputs)\n",
      "        except OutputParserException as e:\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                raise_error = not self.handle_parsing_errors\n",
      "            else:\n",
      "                raise_error = False\n",
      "            if raise_error:\n",
      "                raise e\n",
      "            text = str(e)\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                observation = 'Invalid or incomplete response'\n",
      "            elif isinstance(self.handle_parsing_errors, str):\n",
      "                observation = self.handle_parsing_errors\n",
      "            elif callable(self.handle_parsing_errors):\n",
      "                observation = self.handle_parsing_errors(e)\n",
      "            else:\n",
      "                raise ValueError('Got unexpected type of `handle_parsing_errors`')\n",
      "            output = AgentAction('_Exception', observation, text)\n",
      "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "            observation = await ExceptionTool().arun(output.tool_input, verbose=self.verbose, color=None, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            return [(output, observation)]\n",
      "        if isinstance(output, AgentFinish):\n",
      "            return output\n",
      "        actions: List[AgentAction]\n",
      "        if isinstance(output, AgentAction):\n",
      "            actions = [output]\n",
      "        else:\n",
      "            actions = output\n",
      "\n",
      "        async def _aperform_agent_action(agent_action: AgentAction) -> Tuple[AgentAction, str]:\n",
      "            if run_manager:\n",
      "                await run_manager.on_agent_action(agent_action, verbose=self.verbose, color='green')\n",
      "            if agent_action.tool in name_to_tool_map:\n",
      "                tool = name_to_tool_map[agent_action.tool]\n",
      "                return_direct = tool.return_direct\n",
      "                color = color_mapping[agent_action.tool]\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                if return_direct:\n",
      "                    tool_run_kwargs['llm_prefix'] = ''\n",
      "                observation = await tool.arun(agent_action.tool_input, verbose=self.verbose, color=color, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            else:\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                observation = await InvalidTool().arun(agent_action.tool, verbose=self.verbose, color=None, callbacks=run_manager.get_child() if run_manager else None, **tool_run_kwargs)\n",
      "            return (agent_action, observation)\n",
      "        result = await asyncio.gather(*[_aperform_agent_action(agent_action) for agent_action in actions])\n",
      "        return list(result)\n",
      "\n",
      "    def _call(self, inputs: Dict[str, str], run_manager: Optional[CallbackManagerForChainRun]=None) -> Dict[str, Any]:\n",
      "        \"\"\"Run text through and get agent response.\"\"\"\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        color_mapping = get_color_mapping([tool.name for tool in self.tools], excluded_colors=['green', 'red'])\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
      "        iterations = 0\n",
      "        time_elapsed = 0.0\n",
      "        start_time = time.time()\n",
      "        while self._should_continue(iterations, time_elapsed):\n",
      "            next_step_output = self._take_next_step(name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager=run_manager)\n",
      "            if isinstance(next_step_output, AgentFinish):\n",
      "                return self._return(next_step_output, intermediate_steps, run_manager=run_manager)\n",
      "            intermediate_steps.extend(next_step_output)\n",
      "            if len(next_step_output) == 1:\n",
      "                next_step_action = next_step_output[0]\n",
      "                tool_return = self._get_tool_return(next_step_action)\n",
      "                if tool_return is not None:\n",
      "                    return self._return(tool_return, intermediate_steps, run_manager=run_manager)\n",
      "            iterations += 1\n",
      "            time_elapsed = time.time() - start_time\n",
      "        output = self.agent.return_stopped_response(self.early_stopping_method, intermediate_steps, **inputs)\n",
      "        return self._return(output, intermediate_steps, run_manager=run_manager)\n",
      "\n",
      "    async def _acall(self, inputs: Dict[str, str], run_manager: Optional[AsyncCallbackManagerForChainRun]=None) -> Dict[str, str]:\n",
      "        \"\"\"Run text through and get agent response.\"\"\"\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        color_mapping = get_color_mapping([tool.name for tool in self.tools], excluded_colors=['green'])\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
      "        iterations = 0\n",
      "        time_elapsed = 0.0\n",
      "        start_time = time.time()\n",
      "        async with asyncio_timeout(self.max_execution_time):\n",
      "            try:\n",
      "                while self._should_continue(iterations, time_elapsed):\n",
      "                    next_step_output = await self._atake_next_step(name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager=run_manager)\n",
      "                    if isinstance(next_step_output, AgentFinish):\n",
      "                        return await self._areturn(next_step_output, intermediate_steps, run_manager=run_manager)\n",
      "                    intermediate_steps.extend(next_step_output)\n",
      "                    if len(next_step_output) == 1:\n",
      "                        next_step_action = next_step_output[0]\n",
      "                        tool_return = self._get_tool_return(next_step_action)\n",
      "                        if tool_return is not None:\n",
      "                            return await self._areturn(tool_return, intermediate_steps, run_manager=run_manager)\n",
      "                    iterations += 1\n",
      "                    time_elapsed = time.time() - start_time\n",
      "                output = self.agent.return_stopped_response(self.early_stopping_method, intermediate_steps, **inputs)\n",
      "                return await self._areturn(output, intermediate_steps, run_manager=run_manager)\n",
      "            except TimeoutError:\n",
      "                output = self.agent.return_stopped_response(self.early_stopping_method, intermediate_steps, **inputs)\n",
      "                return await self._areturn(output, intermediate_steps, run_manager=run_manager)\n",
      "\n",
      "    def _get_tool_return(self, next_step_output: Tuple[AgentAction, str]) -> Optional[AgentFinish]:\n",
      "        \"\"\"Check if the tool is a returning tool.\"\"\"\n",
      "        (agent_action, observation) = next_step_output\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        if agent_action.tool in name_to_tool_map:\n",
      "            if name_to_tool_map[agent_action.tool].return_direct:\n",
      "                return AgentFinish({self.agent.return_values[0]: observation}, '')\n",
      "        return None\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62e35a8ac196cebb1fa877b6693ec78f in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The 'AgentExecutor' class does not have a 'prompt' attribute.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The 'AgentExecutor' class does not have a 'prompt' attribute.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(agent.agent.llm_chain.prompt.template)\n",
    "executor.run(\"AttributeError: 'AgentExecutor' object has no attribute 'prompt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PlanAndExecute' object has no attribute 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josephblazick/Documents/demand-forecasting-app/_helpers/langchain_docs.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(agent\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mtemplate)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PlanAndExecute' object has no attribute 'agent'"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "Questions about Langchain codebase: Answers your question using the markdown files found in the langchain documeentation repository. This function is best used when you want examples of how to use particular classes or functions., args: {{{{'tool_input': {{{{'type': 'string'}}}}}}}}\n",
      "Summarise langchain docs: Give a summary of documents retrieved from the markdown files found in the langchain documeentation repository. This function is best used when you want a general summary of how to use langchain modules or classes, args: {{{{'tool_input': {{{{'type': 'string'}}}}}}}}\n",
      "LangChain Class Lookup: Lookup for class definitions in the langchain codebase. You should use this function when you need to see the source code related to a particular class, args: {{{{'tool_input': {{{{'type': 'string'}}}}}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or Questions about Langchain codebase, Summarise langchain docs, LangChain Class Lookup\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n"
     ]
    }
   ],
   "source": [
    "print(agent.executor.chain.agent.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
